\documentclass[a4paper,12pt]{article}
\usepackage{stdtemplate}

\title{MAT354 Complex Analysis}
\author{Jonah Chen}
\date{}
\begin{document}
\maketitle
\sffamily

\section{Rational Functions}
\subsection{Classification of rational functions of order 2}
(up to fractional linear transformations of the source and target):
\begin{enumerate}
    \item One double pole $\beta$
    \item Two distinct poles $a,b$
\end{enumerate}

In case 1: Make a fractional linear transformation to move $\beta$ to $\infty$
\begin{equation}
    z=\beta+\frac{1}{\zeta}
\end{equation}
We set a rational function with double pole at $\infty$, i.e. a polynomial of degree $2$
\begin{align}
    w&=az^2+bz+c\\
    &=a\left(z+\frac{b}{2a}\right)^2-\frac{b^2}{4a}+c\\
\end{align}
Making a change of coordinates in the source and the target
\begin{align}
    w_1&=w+\frac{b^2}{4a}-c\\
    z_1&=z+\frac{b}{2a}\\
\end{align}
so we have $w_1=z_1^2$

In case 2: Make a fractional linear transformation to move $a,b$ to $0,\infty$.
\begin{align}
    w=\frac{z-b}{z-a}
\end{align}

Rational function of order 2 with poles at $0,\infty$ can be written $w=Az+B+\frac{C}{z}$. Make the coefficients of $z$ and $1/z$ equal by $z_1=\sqrt{\frac{A}{C}}z$ and $w_1=\frac{1}{A}(w-B)$ then $w=z+\frac{1}{z}$.

\subsection{Rational functions of order 1}
Fractional linear transformation \begin{align}
    w=S(z)=\frac{az+b}{cz+d}, ad-bc\neq0
\end{align}
Note that $S(\infty)=a/c$ and $S(-d/c)=\infty$.

We want to show that all fractional linear transformations can be written as a composition of translation, inversion, homothety

For $c=0$, $w=az+b$ which is a translation, homothety.

For $c\neq0$, \begin{equation}
    \frac{az+b}{cz+d}=\frac{\frac{a}{c}(z+d/c)+b+\frac{bc-ad}{c^2}}{z+d/c}=\frac{a}{c}+\frac{bc-ad}{c^2}\frac{1}{z+d/c}
\end{equation}
This is a composition of \begin{enumerate}
    \item translation: $z_1=z+d/c$
    \item inversion: $z_2=1/z_1$
    \item homethety: $z_3=\frac{bc-ad}{c^2}\cdot z_2$
    \item translation: $z_4=z_3+a/c$
\end{enumerate}

\begin{theorem}
    Given any 3 distinct points $z_2,z_3,z_4$, $\exists!$ fractional linear transformation $S:z_2,z_3,z_4\mapsto 1,0,\infty$
    \begin{proof}
        \begin{equation}
            S(z)=\begin{cases}
                \frac{z-z_3}{z-z_4}\Big/\frac{z_2-z_3}{z_2-z_4} & \text{otherwise}\\
                \frac{z-z_3}{z-z_4} & \text{if }z_2=\infty\\
                \frac{z_2-z_4}{z-z_4} & \text{if }z_3=\infty\\
                \frac{z-z_3}{z_2-z_3} & \text{if }z_4=\infty
            \end{cases}
        \end{equation}
        Suppose also $T:z_2,z_3,z_4\mapsto 1,0,\infty$. Consider $ST\inv:1,0,\infty\mapsto 1,0,\infty$. $ST\inv$ is also a fractional linear transformation $\frac{az_b}{cz+d}$

        Given any pair of circles/lines
    \end{proof}
\end{theorem}
\begin{definition}[Cross ratio]
    \begin{equation}
        (z_1:z_2:z_3:z_4)=S(z_1)
    \end{equation}
    is the cross ratio of $z_1,z_2,z_3,z_4$.
\end{definition}
\begin{theorem}
    \begin{enumerate}
        \item If $z_1,z_2,z_3,z_4$ are distinct points, and $T$ is a fractional linear transformation, then\begin{equation}
            (z_1:z_2:z_3:z_4)=(Tz_1:Tz_2:Tz_3:Tz_4)
        \end{equation}
        \item $(z_1:z_2:z_3:z_4)$ is real if and only if $z_1,z_2,z_3,z_4$ lie on a circle or a line.
    \end{enumerate}
    \begin{proof}
        \begin{enumerate}
            \item Let $Sz=(z:z_2:z_3:z_4)$. Then, $ST\inv:Tz_2,Tz_3,Tz_4\mapsto1,0,\infty$. Then, $(Tz_1:Tz_2:Tz_3:Tz_4)$ is by definition equal to $Tz_1$ under the fractional linear transformation that takes $Tz_2,Tz_3,Tz_4$ to $1,0,\infty$, which is precisely $ST\inv$. So, $(Tz_1:Tz_2:Tz_3:Tz_4)=ST\inv(Tz_1)=Sz_1=(z_1:z_2:z_3:z_4)$.
            \item First, we show the image of the real axis under fractional linear transformation $T\inv$ is either a circle of line.
            
            $w=T\inv(z)$ for $z\in\R$, we want to see that $w$ satisfies the equation of a circle or line. 
            
            We are interested in all $w$ such that $z=Tw=\frac{aw+b}{cw+d}$ is real. If $z\in\R$, then $Tw=\overline{Tw}$ and \begin{align}
                \frac{aw+b}{cw+d}=\frac{\bar a\bar w+\bar b}{\bar c\bar w+\bar d}\\
                (aw+b)(\bar c\bar w+\bar d)=(cw+d)(\bar a\bar w+\bar b)\\
                (\underbrace{a\bar c-\bar ac}_\text{imaginary})|w|^2+\underbrace{(a\bar d-\bar bc)w+(b\bar c-\bar ad)}_\text{imaginary}+\underbrace{b\bar d-\bar bd}_\text{imaginary}=0
            \end{align}
            If $a\bar c-\bar ac\neq 0$, then this is an equation of a circle. If $a\bar c-\bar ac=0$, then this is an equation of a line.

            Next, $Sz=(z:z_2:z_3:z_4)$ is real on the image of the real axis under $S\inv$ and nowhere else. $S\inv:1,0,\infty\mapsto z_2,z_3,z_4$
        \end{enumerate}
    \end{proof}
\end{theorem}

Fractional linear transformations $T$ takes the set of all circles and lines in the complex plane to itself. 

Given any pair of circles/lines, there is a fractional linear transformation taking one to the other.


\begin{example}
    Fractional linear transformation that takes the upper half plane $H^+$ to the unit disk $D$ and the real axis to the unit circle.

    We will take $i$ to $0$, so the numerator should be $z-i$. $w=\frac{z-i}{z+i}:i\mapsto0,0\mapsto-1,\infty\mapsto1,1\mapsto-i$
\end{example}

\section{Holomorphic Functions}
\begin{itemize}
    \item $f(z)$ complex valued functions in an open set $\Omega\subset\C$ or $\Omega\subset\C\cup\{\infty\}$
    \item $f$ is holomorphic if $\lim_{h\to0}\frac{f(z+h)-f(z)}{h}$ exists. i.e. for some $c\in\C, f(z+h)-f(z)=ch+\varphi(h)h$ where $\varphi(h)\in o(h)$.
    \item This is similar to the definition of the derivative from an open set in the plane to an open set in the plane. (writing $z=x+iy,f(z)=u+iv,c=a+ib,h=\xi+i\eta$ and $f:(x,y)\mapsto(u,v)$)
    \item The derivative at $z$ takes\begin{align}
        h&\mapsto ch\\
        \begin{pmatrix}
            \xi\\
            \eta
        \end{pmatrix}&\mapsto\begin{pmatrix}
            a & -b\\
            b & a
        \end{pmatrix}\begin{pmatrix}
            \xi\\
            \eta
        \end{pmatrix}
    \end{align}
    The matrix $\begin{pmatrix}
        a & -b\\
        b & a
    \end{pmatrix}=\begin{pmatrix}
        \partialderivative{u}{x} & \partialderivative{u}{y}\\
        \partialderivative{v}{x} & \partialderivative{v}{y}
    \end{pmatrix}$
    \item For a function to be holomorphic, it requires an additional constraint than being simply differentiable. $\partialderivative{u}{x}=\partialderivative{v}{y}$ and $\partialderivative{u}{y}=-\partialderivative{v}{x}$. This is the Cauchy-Riemann equations. Or, $\partialderivative{f}{x}+i\partialderivative{f}{y}=0$.
    \item The derivative at $z$ is a linear transformation $h\mapsto ch$.
    \item The jacobian determinant is $a^2+b^2=|f'(z)|^2$.
    \item Consider $f(x,y)$ differentiable, but complex valued. The differential $\dd f=\partialderivative{f}{x}\dd x+\partialderivative{f}{y}\dd y$. For example, $z=x+iy$ or $\bar z=x-iy$. Then, $\dd z=\dd x+i\dd y$ and $\dd\bar z=\dd x-i\dd y$.
    \item Then we have $\dd x=\frac{1}{2}(\dd z+\dd\bar z)$ and $\dd y=\frac{1}{2i}(\dd z-\dd\bar z)$. Then, \begin{align}
        \dd f=\frac{1}{2}\left(\partialderivative{f}{x}-i\partialderivative{f}{y}\right)\dd z+\frac{1}{2}\left(\partialderivative{f}{x}+i\partialderivative{f}{y}\right)\dd\bar z
    \end{align}
    \item So, we \redbf{define}\begin{align}
        \partialderivative{f}{z}=\frac{1}{2}\left(\partialderivative{f}{x}-i\partialderivative{f}{y}\right)\\
        \partialderivative{f}{\bar z}=\frac{1}{2}\left(\partialderivative{f}{x}+i\partialderivative{f}{y}\right)
    \end{align}
    \item Thus, we can write the 1-form $\dd f=\partialderivative{f}{z}\dd z+\partialderivative{f}{\bar z}\dd\bar z$.
    \item $\partialderivative{}{z}$ and $\partialderivative{}{\bar z}$ are defined as the dual basis for $\dd z,\dd\bar z$.
    \item We can rewrite the Cauchy-Riemann equations as $\partialderivative{f}{\bar z}=0$. This means for holomorphic functions, it's \redbf{only} a function of $z$, \redbf{not} $\bar z$.
    \begin{definition}[Harmonic Function]
        $f(x,y)$ is a \textbf{harmonic function} if $f\in C^2$ and $\Delta f=0$, or $\frac{\partial^2f}{\partial z\partial\bar z}=0$. (laplace equation) 
    \end{definition}
    \item We will see that holomorphic functions are harmonic. (but we need to first show we can differentiate holomorphic functions twice) So, the real and imaginary parts of holomorphic functions are also harmonic.
    \item Remark: $\partialderivative{f}{\bar z}=0\iff\partialderivative{\bar f}{z}=0$. Why? Consider $f=u+iv,\bar f=u-iv$.
    \begin{align}
        \partialderivative{f}{\bar z}&=\frac{1}{2}\left(\partialderivative{f}{x}+i\partialderivative{f}{y}\right)\\
        \overline{\partialderivative{f}{\bar z}}&=\frac{1}{2}\left(\partialderivative{\bar f}{x}-i\partialderivative{\bar f}{y}\right)=\partialderivative{\bar f}{z}\\
    \end{align}
    \begin{lemma}
        If $f(z)$ is holomorphic in a connected open set $\Omega$ and $f'(z)=0$ in $\Omega$, then $f$ is constant.
        \begin{proof}
            \begin{equation}
                \dd f=\underbrace{\partialderivative{f}{z}}_{0}\dd z+\underbrace{\partialderivative{f}{\bar z}}_{0\text{ holomorphic}}\dd\bar z=0
            \end{equation}
        \end{proof}
    \end{lemma}
    \begin{proposition}
        Given $f(z)$ is holomorphic in a connected open set $\Omega$, then
        \begin{enumerate}
            \item If $|f(z)$ is constant, then $f(z)$ is constant.
            \item If $\Re(f(z))$ is constant, then $f(z)$ is real.
        \end{enumerate}
        \begin{proof}
            \begin{enumerate}
                \item $|f(z)|^2=f(z)\overline{f(z)}$ is constant, so \begin{align}
                    0=\partialderivative{|f|^2}{z}=\partialderivative{f}{z}\bar f+f\cancel{\partialderivative{\bar f}{z}}=\partialderivative{f}{z}\bar z
                \end{align}
                so either $\bar f=0$ so $f=0$ thus $f$ is constant or $\partialderivative{f}{z}=0$ so $f$ is constant.
                \item $\Re(f)=f+\bar f$ is constant, so \begin{align}
                    0=\partialderivative{(f+\bar f)}{z}=\partialderivative{f}{z}+\cancel{\partialderivative{\bar f}{z}}=\partialderivative{f}{z}
                \end{align}
                so $\partialderivative{f}{z}=0$ and $f$ is constant.
            \end{enumerate}
        \end{proof}
    \end{proposition}
\end{itemize}
\subsection{Mapping Properties}
Suppose $f$ is holomorphic at some point $z_0.$ The \bluebf{tangent mapping} of $f$ at $z_0$ is \begin{equation}
    w=f(z_0)+f'(z_0)(z-z_0),
\end{equation}
if $f'(z)\neq 0, $ then the tangent mapping preserves angles and their orientation. \begin{definition}[Conformal Mapping]
    A mapping $f$ is \textbf{conformal} if $f$ is holomorphic and $f'(z_0)\neq 0$. i.e. if $f$ preserves angles and orientation.
\end{definition}
\begin{lemma}
    A $\R$-linear transformation $\C\to\C$ which preserves angles is of the form either $w=cz$ or $w=c\bar z.$
\end{lemma}
Consider $w=f(z)$ in a connected open set $\Omega.$ If $f$ is treated as a function from $\R^2\to\R^2$ has $\det f'\neq0$ in $\Omega.$

If $f$ preserves angles at every point in $\Omega,$ then $\partialderivative{f}{z}=0$ or $\partialderivative{f}{\bar z}=0.$ They cannot be both zero at the same point, as otherwise $\det f'=0$ at that point. As $f\in C^1,$ the partial derivatives are continuous. This means $\{z\in\Omega|\partialderivative{f}{z}=0\},\{z\in\Omega|\partialderivative{f}{\bar z}=0\}$ are disjoint sets, and their union is $\Omega.$ Since $\Omega$ is connected, one of them must be empty.

So, either $\partialderivative{f}{\bar z}=0$ throughout $\Omega\implies f$ is holomorphic, or $\partialderivative{f}{\bar z}=0$ throughout $\Omega\implies f$ is anti-holomorphic.

\begin{theorem}
    $f$ preserves angles at every point in $\Omega\iff f$ is either holomorphic or anti-holomorphic in $\Omega.$
\end{theorem}

\begin{theorem}[Inverse Function]
    Suppose $f$ is holomorphic in a neighborhood of $z_0$ and $f'(z_0)\neq0.$ Then there are neighborhoods $U$ of $z_0$ and $V$ of $w_0=f(z_0)$ such that $f$ maps $U$ \bluebf{onto} $V,$ with an inverse $z=g(w)$ which is holomorphic in $V.$ And,\begin{align}
        g'(w)=\frac{1}{f'(z)}.
    \end{align}
    \begin{proof}[Proof (to be completed later)] We will use the fact that partial derivatives of holomorphic functions are continuous, which we will prove later.

    If $f'(z)=\begin{pmatrix}
        a&-b\\
        b&a
    \end{pmatrix}$
    and $g'$ is the inverse, then $g'(w)=\frac{1}{a^2+b^2}\begin{pmatrix}
        a&b\\
        -b&a
    \end{pmatrix},$ so $g$ satisfies the cauchy riemann equations and $g$ is holomorphic.
    \end{proof}
\end{theorem}

\section{Power Series}
\begin{itemize}
    \item A complex power series $f(w)=\sum_{n=0}^\infty a_nw^n.$ Note that $w$ is not a complex number, it's just a symbol. Complex power series means $a_n\in\C.$
    \item Suppose we have another power series $g(z)=\sum_{p=0}^\infty b_pz^p.$ We want to compose \begin{align}
        (f\circ g)(z)=a_0+a_1(b_0+b_1z+\cdots)+a_2(b_0+b_1z+\cdots)^2+\cdots
    \end{align} 
    \item First we need to ask if this even make sense? The answer is yes if $b_0=0.$ However, in calculus every formal power series is the taylor series of some $C^\infty$ functions, which can be composed. So why do we have this restriction?
    \item Consider taylor series of $f(g(z))$ at $z=z_0.$ Let $w_0=g(z_0)$ and the taylor series at $w_0$ is \begin{align}
        f(w)=\sum_{n=0}^\infty a_n(w-w_0)^n.
    \end{align}
    Then we replace $w$ with the taylor series for $g$ at $z_0,$ with $b_0=w_0$ so these does not have constant term.
\end{itemize}
\begin{definition}[Formal Derivative]
    We define $f(0)=a_0$ and the \bluebf{formal derivative} of $f(w)$ as \begin{align}
        f'(w)=\sum_{n=1}^\infty na_nw^{n-1}.
    \end{align}
\end{definition}
\begin{theorem}[Formal inverse function]
    Given formal power series $f(w)=\sum_{n=0}^\infty a_nw^n.$ There is a power series $g(z)=\sum_{p=0}^\infty b_pz^p$ such that $b_0=0$ and $f\circ g=\mathrm{id}$ where $\mathrm{id}(z)=z$ \redbf{iff} $f(0)=0,f'(0)\neq0.$ In that case $g$ is uniquely determined by $f$ and $g\circ f=\mathrm{id}$ also.
    \begin{proof}[Proof by method of undetermined coefficients]
        We are trying to solve \begin{align}
            a_0+a_1(b_1z+b_2z^2+\cdots)+a_2(b_1z+b_2z^2+\cdots)^2+\cdots=z.
        \end{align}
        We know right away that $a_0=0$ and $a_1b_1=1.$ so we know that $a_0=0$ and $a_1\neq=$ are necessary conditions. Conversely, they are sufficient to solve for \bluebf{unique} coefficients of $g$.

        The coefficient of $z^n$ on the LHS is the same as the coefficient of $z^n$ in \begin{align}
            \cancel{a_0}+a_1g(z)+\cdots+a_ng(z)^n=a_1b_n+P(a_2,\dots,a_n,b_1,\dots,b_{n-1}).
        \end{align}
        And $b_1=1/a_1,$ thus $b_n$ can be calculated recursively.

        Since $g(0)=0$ and $g'(0)\neq0,$ there is a unique formal power series $f_1(w)$ s.t. $g\circ f_1=\mathrm{id}.$\begin{align}
            f_1=\mathrm{id}\circ f_1=(f\circ g)\circ f_1=f\circ(g\circ f_1)=f
        \end{align}
    \end{proof}
\end{theorem}
\begin{proposition}
    If $f=\sum_{n=0}^\infty a_nw^n$ and $g=\sum_{p=0}^\infty b_pw^p$ are convergent power series, then $f\circ g$ is also convergent. In fact, take $r>0$ s.t. $\sum_{p=1}^\infty|b_p|r^p<R(f)$ the radius convergence of $f.$ Then,\begin{enumerate}[label=(\arabic*)]
        \item $R(f\circ g)\geq r$
        \item If $|z|<r$ then $|g(z)<R(f).$
        \item $f(g(z))=(f\circ g)(z)$ (by rearrangement of absolute convergent series) where RHS is formal power series composition and LHS is substituting the value of $g(z)$ into $f.$
    \end{enumerate}
    \begin{proof}[Proof of (1)]
        \begin{align}
            \sum_{n=0}^\infty|a_n|\left(\sum_{p=1}^\infty|b_p|r^p\right)^n=:\sum_{k=0}^\infty\gamma_kr^k<\infty
        \end{align}
        Say $(f\circ g)(z)=\sum c_kz^k.$ By triangle inequality, $|c_k|\leq\gamma_k.$ As $\sum\gamma_kr^k<\infty,$ then $\sum c_k\gamma^k$ is convergent.
    \end{proof}
\end{proposition}
\begin{theorem}[Reciprocal] 
    If $f(z)=\sum_{n=0}^\infty a_nz^n$ and $a_0\neq0$ then there is an unique power series $g(z)$ s.t. $f(z)=g(z)=1.$ If $f$ has a positive radius of convergence, then so does $z.$
    \begin{proof}
        As $a_0\neq0,$ then WLOG $a_0=1.$ Write $f(z)=1-h(z)$ then \begin{align}
            f(z)\inv=(1-h(z))\inv=1+\sum_{n=1}^\infty w^n\quad \text{where }w=h(z).
        \end{align}
    \end{proof}
\end{theorem}
\begin{theorem}[Inverse function for convergent power series]
    In the previous statement, if $f(w)$ has a positive radius of convergence, then so does $g(z).$
    \begin{proof}
        By direct estimate OR follows from inverse function theorem for holomorphic functions once we know holomorphic function has infinite taylor series that converges.
    \end{proof}
\end{theorem}

\subsection{Logarithmic Function}
\begin{itemize}
    \item The principal branch of $\log z$ is defined on the largest simply connected set that does not contain zero, which we will choose $\C\setminus(-\infty,0].$ In this domain, there is a unique value of $\arg z\in(-\pi,\pi),$ we will call it $\mathrm{Arg}(z).$
    \item We can show that this is continuous by showing it is continuous on $S'\setminus\{-1\}.$ We can show this by its the fact its inverse $z=e^{i\theta}$ is continuous on $[-(\pi-\epsilon),\pi+\epsilon]$ hence the it's the inverse of an bijection on compact hausdorff space.
    \item The principal branch of $\log z$ is defined as $\log|z|+i\mathrm{Arg}\,z,$ which is continuous on its entire domain $\C\setminus(-\infty,0].$ Note that this is equal to the real logarithm if $z\in\R.$
    \begin{proposition}
        The power series $f(z)=\sum_{n=1}^\infty(-1)^{n+1}\frac{z^n}{n}$ converges if $|z|<1$ and the sum is equal to the principal branch of $\log(1+z).$ \begin{proof}
            The power series $f(z)$ and $g(w)=\sum_{n=1}^\infty\frac{w^n}{n!}=e^w-1$ are inverses. The proof is by MAT157 since the coefficients here are all real with $g(f(z))=z$ when $|z|<1$.

            We also know that $e^{f(z)}=1+z$ and it's the principal branch because $f(0)=\log 1=0$
        \end{proof}
    \end{proposition}
    \begin{definition}[Power]
        \begin{align}
            z^\alpha=e^{\alpha\log z}
        \end{align}
        where $\alpha\in\C,z\neq0.$ Note that for fixed $\alpha,\: z^\alpha$ is a many-valued function of $z.$ This has a branch in any \bluebf{domain} (connected open subset of $\C$) where $\log$ has a branch. \redbf{Any} branch of $\log z$ in $\Omega$ defines a branch of $z^\alpha.$
    \end{definition}
    \begin{itemize}
        \item e.g. The \bluebf{binomial series} $(1+z)^\alpha=e^{\alpha\log(1+z)}$ and its power series expansion in $|z|<1$ is $\sum\binom{\alpha}{n}z^n.$
    \end{itemize}
\end{itemize}

Mapping Properties of Holomorphic Functions
\begin{itemize}
    \item $w=z^\alpha$ for real, positive $\alpha$ maps angles $\theta$ to an angle $\alpha\theta.$
    \item In general $z^\alpha$ is not 1-1 if $\alpha\neq1,$ and is multi-valued if $\alpha$ is fractional.
    \item Often, we will use a branched covering (mapping $X\to\C$) so we can have a single valued branch. Consider the multi-valued function $w=z^{1/2}.$ Consider \begin{align}
        X=\{(z,w)\in\C^2|z=w^2\}
    \end{align}
    $X$ is a manifold (it is a graph of a continuous function) with local coordinate $w.$
    \item This multi-valued function $w=z^{1/2}$ lifts to a single valued $(w,z)\mapsto w$ by the covering surface $X.$ $X$ is an example of a \bluebf{Riemann surface}.
\end{itemize}

Consider a mapping that takes the upper half plane $H^+=\{z\in\C|\Im(z)>0\},$ and consider the mapping that takes $H^+\to D=\{z\in\C|z|<1\},$ We can use a fractional linear transformation \begin{align}
    w=\frac{z-i}{z+i}
\end{align}
this takes $i\mapsto0.$ We also know that it maps $\R$ to $S^1$ as we can pick three points $0,1,\infty\in\R$ and we know $0\mapsto-1.$ We know this preserves orientations so $1\mapsto-i$ and $\infty\mapsto1.$

Now, we want to find a conformal mapping of a circular wedge onto $D$ or $H^+.$

If  circular wedge is formed by two circles intersecting in $a$ and $b,$ first use a fractional linear transformation $\zeta=\frac{z-a}{z-b}$ to map $a\mapsto0$ and $b\mapsto\infty.$ This takes the two circles into rays. Then, we can rotate the region by multiplying a complex number $e^{i\theta}$ and then change the angle by taking $w=e^{i\theta}\zeta^\alpha$ for some power $\alpha.$

In the case they are degenerate, and only intersect at $a,$ we take $\zeta=\frac{1}{z-a}$ which leads to two parallel lines. Then we can rotate and stretch it so that they become the real line and the line $\Im(z)=\pi,$ then $\exp$ will map it to the upper half plane.

\textbf{Exercise:} Find a conformal mapping that takes the complement of the line segment to the interior (or exterior) of the unit disk. We will apply \begin{equation}
    z_1=\frac{z-1}{z+1}
\end{equation}
will map the interval $[-1,1]$ to $(-\infty,0].$ Then we can apply \begin{align}
    z_2=z_1^{1/2}
\end{align}
This maps the set to the right half plane. Finally, \begin{align}
    w=\frac{z_2-1}{z_2+1}=z-\sqrt{z^2-1}
\end{align}
will map the right half plane into the interior of the unit disk (flipping the fraction maps to exterior). Check which branch of square root we need to use? Finally, show that $z=\frac{1}{2}(w+1/w)$

\subsection{Mapping Properties of $\exp$ and $\log$}
\begin{itemize}
    \item We know that $w=e^z$ is periodic with period $2\pi i,$\begin{align}
        e^z=e^xe^{iy}\\
        &=e^x(\cos y+i\sin y)\\
    \end{align}
    \item The exponential maps a vertical line to circle about $0,$ a horizontal line to a ray through $0,$ and any other line to a logarithmic spiral.
    \item The exponential is not injective. To make it single-valued, we need to restrict its domain. The image of $e^z$ on $a<\Im z<b$ is a wedge in the complex plane $a<\arg w<b.$
    \item The logarithm is clearly multi-valued. Can we construct a riemann surface for $w=\log z$?
    \begin{tikzcd}  
    X \arrow[d,"\text{covering}"] \arrow[r, "\text{single value}"] & \C \\
    \C \arrow[ru,"\log z"] &
    \end{tikzcd}
    Let $X=\{(z,w)\in\C^2|z=e^w\}$ then again the single-valued function $(w,z)\to w$ is singled valued.
\end{itemize}
Now we can try to map the open strip $-i\pi/2<\Im(z)<i\pi/2$ to the unit disk. First we use $\zeta=e^z$ to map to the right half plane, then $w=\frac{\zeta-1}{\zeta+1}.$
\section{Analytic functions}
\begin{definition}[Analytic Function]
    A function $f$ is \bluebf{analytic} in an open set $\Omega$ if it has a convergent power series representation at every point $z_0\in\Omega.$

    i.e. $\forall\,z_0\in\Omega$ there is a power series $\sum a_n(z-z_0)^n$ such that $f(z)=\sum a_n(z-z_0)^n$ when $|z-z_0|<R$ for some $R>0.$
\end{definition}
\begin{itemize}
    \item If $f(z)$ has convergent power series representation at $z_0,$ then there is a convergent power series $g(z)$ at $z_0$ such that $g'(z)=f(z)$ in some disk $|z-z_0|<R,$ where $R$ is the radius of convergence of $f.$ We know \begin{align}
        f(z)&=\sum_{n=0}^\infty a_n(z-z_0)^n\\
        g(z)&=c+\sum_{n=0}^\infty\frac{a_n}{n+1}(z-z_0)^{n+1}\\
    \end{align}
    The primitive is uniquely determined up to a constant.
    \item \textbf{Question:} Does a convergent power series define an analytic function?
    \begin{proposition}
        If $f(z)=\sum a_nz^n$ is a convergent power series with radius of convergence $R,$ then $f(z)$ is analytic in $|z|<R.$
        \begin{proof}
            Note what we need to show. For any $z_0$ with $|z_0|<R,$ then $f(z)$ has convergent power series representation at $z_0$ with radius of convergence $R-|z_0|.$\begin{align}
                f(z)&=\sum a_nz^n\\
                &=\sum a_n(z_0+(z-z_0))^n\\
                &=\sum_{n=0}^\infty a_n\sum_{k=0}^n\binom{n}{k}z_0^{n-k}(z-z_0)^k
            \end{align}
            Note that if we take \begin{align}
                \sum_{n=0}^\infty|a_n|\left(|z_0|+|z-z_0|\right)^n&=\sum_{n=0}^\infty|a_n|\sum_{k=0}^n\binom{n}{k}|z_0|^{n-k}|z-z_0|^k
            \end{align}
            We know this series is absolutely convergent. So we can change the order of summation  to conclude \begin{align}
                f(z)=\sum_{k=0}^\infty\left(\sum_{n=k}^\infty a_n\binom{n}{k}z_0^{n-k}\right)(z-z_0)^k
            \end{align}
        \end{proof}
    \end{proposition}
    \item We notice that the inner sum\begin{align}
        \frac{1}{k!}f^{(k)}(z_0)=\sum_{n=k}^\infty a_n\binom{n}{k}z_0^{n-k}
    \end{align} is the $k$th derivative of $f$ at $z_0,$ so $f$ is holomorphic.
\end{itemize}
\subsection{Analytic Continuation}
\begin{theorem}
    Given $f(z)$ is analytic in a domain $\Omega$ and $z_0\in\Omega,$ then the following are equivalent\begin{enumerate}
        \item $f^{(n)}(z_0)=0$ for all $n\geq 0.$
        \item $f$ is identically $0$ in a neighborhood of $z_0.$
        \item $f$ is identically $0$ in $\Omega.$
    \end{enumerate}
    \begin{proof}
        $(3)\implies(1)$ is trivial, $(1)\implies(2)$ can be shown from the convergent power series representation of $f$ at $z_0$ (as the coefficient are the derivatives).
        
        To show $(2)\implies(3)$, we define \begin{align}
            \Omega'=\{z\in\Omega|f=0\text{ in a neighborhood of }z\text{ in }\Omega\}.
        \end{align}
        Clearly $\Omega'\neq\emptyset$ because $z_0\in\Omega.$

        $\Omega'$ is open by definition.

        $\Omega'$ is also closed. Take $z\in\overline{\Omega'}.$ Then, $f^{(n)}(z)=0$ for all $n\geq 0$ by continuity. Then $f=0$ in a neighborhood of $z,$ by $(1)\implies(2).$ So $z\in\Omega'.$ thus $\Omega'$ is closed. 

        Hence, $\Omega=\Omega'.$
    \end{proof}
    \begin{corollary}
        \begin{enumerate}
            \item If $f,g$ are analytic in domain $\Omega$ and $f=g$ in a neighborhood of some point then $f=g$ in $\Omega.$
            \item The ring $\mathcal A(\Omega)$ if analytic functions in a domain $\Omega$ is an \bluebf{integral domain}.
        \end{enumerate}
        \begin{proof}
            The proof of $(1)$ is trivial using $h=f-g.$ For $(2),$ suppose $f,g\in\mathcal{A}(\Omega)$ and $fg=0.$ Suppose $f\neq0$ then there is $z_0$ s.t. $f$ is non-vanishing in a neighborhood in a neighborhood $U$ of $z_0.$ So $g=0$ in $U$ hence $g=0$ in $\Omega.$
        \end{proof}
    \end{corollary}
\end{theorem}
\begin{itemize}
    \item Integral domains are good, but it is better to work with fields. Hence, we will now analyze the zeros and poles.
    \item Consider $f$ is analytic in a neighborhood of $z_0.$ Then $f(z)=\sum a_n(z-z_0)^n$ is a convergent power series with radius of convergence $R.$ Suppose $f(z_0)=0$ but $f\neq0.$
    \item Let $k$ be the smallest integer s.t. $f^{(k)}(z_0)\neq0$ (i.e. $a_k\neq0$) Then, we define $g$ s.t. $f(z)=(z-z_0)^kg(z).$ Then, \begin{align}
        g(z)=\sum_{n=k}^\infty a_n(z-z_0)^{n-k}
    \end{align}
    \item $k$ is the \bluebf{order} or \bluebf{multiplicity} of the zero at $z_0,$ characterized by $f^{(k)}(z_0)\neq0,$ but $f^{(j)}(z_0)=0$ for $j<k.$
    \item This shows the zero is \bluebf{isolated} meaning $f(z)\neq0$ in $0<|z-z_0|<\epsilon$ for any $\epsilon>0.$
    \item If we make a local change of variable near $z,$\begin{align}
        \zeta=(z-z_0)g(z)^{1/k}.
    \end{align}
    This is a change of coordinates because its derivative is nonzero. Then, $f(z(\zeta))=\zeta^k.$
    \item We now consider the quotients of analytic functions $f(z)/g(z)$ where $g$ is not identically zero. $f(z)/g(z)$ is well-defined and analytic in a neighborhood of $z_0$ if and only if $g(z)$ is analytic in a neighborhood of $z_0$ where $g(z_0)\neq0.$
    \item What if $g(z_0)=0$? We can try to factor out terms of $z-z_0$ so that $f_1(z_0)\neq0$ and $g_1(z_0)\neq0$ and\begin{align}
        f(z)&=(z-z_0)^k f_1(z)\\
        g(z)&=(z-z_0)^l g_1(z)
    \end{align}
    Then \begin{align}
        \frac{f(z)}{g(z)}=(z-z_0)^{k-l}\frac{f_1(z)}{g_1(z)}
    \end{align}
    We know that $f_1(z)/g_1(z)$ is analytic and nowhere vanishing in a neighborhood of $z_0.$ There are two cases \begin{itemize}
        \item $k\geq l$ then $f/g$ extends to be analytic at $z_0.$
        \item $k<l$ then $z_0$ is a \bluebf{pole} of $f/g$ of \bluebf{order} $l-k.$ Then, \begin{align}
            \left|\frac{f(z)}{g(z)}\right|\to\infty\text{ as }z\to z_0,
        \end{align}
        so $f/g$ still make sense as a function with values in the Riemann sphere.
    \end{itemize} 
\end{itemize}
\begin{definition}[Meromorphic Function]
    In an open set $\Omega,$ a \bluebf{meromorphic function} is well-defined and analytic in $\Omega\setminus D$ where $D$ is a discrete set, and expressible at in a neighborhood of any point of $\Omega$ as the quotient $f/g$ with $g$ is not identically zero. 
\end{definition}
\begin{itemize}
    \item Meromorphic functions in domain $\Omega$ form a \textbf{field}.
    \item \textbf{Exercise:} If $f(z)$ is meromorphic in $\Omega,$ then $f'(z)$ is also meromorphic in $\Omega$ with the same poles as $f.$ If $z_0$ is a pole of order $k$ of $f(z)$ then $z_0$ is a pole of order $k+1$ of $f'(z)$.
\end{itemize}
\section{Cauchy's Integral Formula}
\begin{itemize}
    \item Review of integration over curves: Let $\Omega\subset\R^2$ be an open set. A curve $\gamma:[a,b]\to\Omega$ where $\gamma(t)=(x(t),y(t)).$
    \item Let a differential $1$ form $\omega=P\dd x+Q\dd y$ where $P,Q$ are continuous function on $\Omega.$ Let $F(t)=P(x(t),y(t))+Q(x(t),y(t))$ Then, \begin{align}
        \int_\gamma\omega=\int_a^bF(t)\dd t.
    \end{align}
    because \begin{align}
        \int_\gamma\omega&=\int_a^b\gamma^*\omega\\
        \gamma^*P&=P\circ\gamma\\
        \gamma^*(\dd x)&=\dd(\gamma^*x)-\dd((x\circ\gamma)(t))=\dd(x(t))
    \end{align}
    \item We also know that this integral is independent of the choice of parametrization of $\gamma.$ Suppose $\delta(u)=\gamma(t(u))$ where $t:[c,d]\to[a,b]$ where $t(c)=a,t(d)=b,t'(u)>0.$ Then, $\delta^*\omega=F(t(u))t'(u)\dd u,$ then \begin{align}
        \int_\delta\omega=\int_\gamma\omega
    \end{align}
    by integration by substitution (MAT157).
    \item If the change of parametrization is orientation reversing (where $t(c)=b,t(d)=a,t'(u)<0$) then \begin{align}
        \int_\delta\omega=-\int_\gamma\omega,
    \end{align}
    as the integral from $c$ to $d$ becomes an integral from $t(c)=b$ to $t(d)=a,$ which is the negative of the integral from $a$ to $b.$
    \item If $\gamma_i=\gamma|_{[t_{i-1},t_i]},$ where $a=t_0<t_1<\cdots<t_n=b,$ then \begin{align}
        \int_\gamma\omega=\sum_{i=1}^n\int_{\gamma_i}\omega.
    \end{align}
    so $\int_\gamma\omega$ makes sense if $\gamma$ is piecewise $C^1.$
    \item When we have a closed curve $\gamma(a)=\gamma(b),$ the integral is independent of the choice of initial and final points.`'
\end{itemize}
\begin{lemma}
    Any two points of a connected open subset $\Omega\subset\R^2$ can be joined by a piecewise $C^1$ curve.
    \begin{proof}
        Fix $a\in\Omega.$ Let $E=\{b\in\Omega|\text{$a$ and $b$ can be joined by piecewise $C^1$ curve}\}.$ If $b\in E$ then a neighborhood of $b$ is in $E.$ Hence, $E$ is open.

        Let $b\in\overline E.$ Then any neighborhood of $b$ will intersect $E.$ Then, $\exists\,c\in E$ in this neighborhood. We can join $c$ and $b$ by a straight line, and $a$ and $c$ by a piecewise $C^1$ curve as $b\in E$. Hence, $b\in E$ and $E$ is closed.

        Clearly, $E\neq\emptyset$ because $a\in E.$ Thus, $E=\Omega.$
    \end{proof}
\end{lemma}
\begin{itemize}
    \item The \bluebf{primitive of $\omega$} is a $C^1$ function $F$ on $\Omega$ s.t. $\omega=\dd F.$ Then, \begin{align}
        \int_\gamma\dd F=\int_{\partial\gamma} F=F(\gamma(b))-F(\gamma(a)).
    \end{align}
    \item If $\Omega$ is connected and $dF=0,$ then $F$ is constant.
    \item As the primitive is easy to integrate, we want to ask given $\omega,$ can we find a primitive?
\end{itemize}
\begin{proposition}
    $\omega$ has a primitive \textbf{iff} $\int_\gamma\omega=0$ for every piecewise $C^1$ \underline{closed} curve $\gamma.$
    \begin{proof}[Proof $\Rightarrow$]
        Suppose $\omega$ has a primitive $F.$ Then for any $\gamma$ \begin{align}
            \int_\gamma\omega=\int_\gamma\dd F=\int_{\partial\gamma}F=F(\gamma(b))-F(\gamma(a))=0.
        \end{align} because $\gamma$ is closed.
    \end{proof}
    \begin{proof}[Proof $\Leftarrow$]
        Fix a base point $x_0\in\Omega.$ Take any piecewise $C^1$ curve $\gamma$ from $x_0$ to $x.$ Then, define \begin{align}
            F(x)=\int_\gamma\omega.
        \end{align}
        This is well defined as if we choose another curve $\delta$ from $x_0$ to $x,$ then the curve $\gamma$ then $\delta$ is a closed curve, and by the hypothesis it is $0$ so $F(x)$ is independent of the choice of $\gamma.$

        Now, we need to show $F$ is $C^1.$ If $h$ is small enough, then we pick $\gamma$ from $x_0$ to $x,$ then a straight line segment $x$ to $x+h.$ \begin{align}
            F(x+h)-F(x)&=\int_{x}^{x+h}P(t,y)\dd t\\
            \lim_{h\to0}\frac{F(x+h)-F(x)}{h}&=\lim_{h\to0}\frac{1}{h}\int_{x}^{x+h}P(t,y)\dd t=P(x,y).
        \end{align}
        by the fundamental theorem of calculus. This can be repeated for the other partial derivatives, and hence $F$ is $C^1.$
    \end{proof}
\end{proposition}
% \begin{theorem}[Cauchy]
%     Let $\omega=P\dd x+Q\dd y$ be a differential form in open $\Omega\subseteq\R^2,$ where $P,Q$ are continuous. Then, $\omega$ has a primitive iff $\int_\gamma\omega=0$ for any piecewise $C^1$ closed curve $\gamma$ in $\Omega.$
% \end{theorem}
\begin{definition}
    $\omega$ is \bluebf{closed} if $\omega$ locally has a primitive. This is equivalent to \begin{enumerate}
        \item $\int_\gamma\omega=0$ whenever $\gamma$ is the boundary of a sufficiently small rectangle $R$ in $\Omega.$
        \item If $\gamma$ is the boundary of any rectangle in $\Omega,$ because any rectangle can be split up into many small rectangles.
    \end{enumerate}
\end{definition}

So every closed differential form $\omega$ \textbf{in a disk} has a primitive. 

Note that closed differential form in a domain $\Omega$ need not have a primitive. Note the following counterexample. Let $\Omega=\C\setminus\{0\}$ and $\omega=\dd z/z.$ Clearly, $\omega$ is closed because locally at each point of $\omega$ there is a branch of $\log$ in a neighborhood of that point, which is a primitive.

However, $\omega$ does not have a global primitive. Let $\gamma(t)=e^{it}$ with $t\in[0,2\pi].$ Then, $z=e^{it}$ so $\dd z=ie^{it}\dd t$ and \begin{align}
    \int_\gamma\frac{\dd z}{z}=\int_0^{2\pi i}\dd t=2\pi i.
\end{align}
Note that the example need not be complex. The imaginary part was \begin{align}
    \dd t=\frac{x\dd y-y\dd x}{x^2+y^2},
\end{align}
where $t=\arctan(y/x),$ which was proven to not have a global primitive in MAT257.

\begin{theorem}
    \textbf{Aside:} assume $P$ and $Q$ are continuous with the following continuous partial derivatives $\partialderivative{P}{y},\partialderivative{Q}{x}$ in some neighborhood of a closed rectangle $A$ and let $\gamma=\partial A.$ Then, Green's theorem says \begin{align}
        \int_\gamma\underbrace{P\dd x+Q\dd y}_{\omega}=\int_A\underbrace{\left(\partialderivative{Q}{x}-\partialderivative{P}{y}\right)\dd x\wedge\dd y}_{\dd\omega}.
    \end{align} 
    \begin{proof}
        We can apply Stoke's theorem, but that is too easy. Let $A=[a_1,a_2]\times[b_1,b_2]$ then \begin{align}
            \int_A\partialderivative{Q}{x}\dd x\wedge\dd y&=\int_{b_1}^{b_2}\left(\int_{a_1}^{a_2}\partialderivative{Q}{x}\dd x\right)\dd y\\
            &=\int_{b_1}^{b_2}\left(Q(a_2,y)-Q(a_1,y)\right)\\
            &=\int_\gamma Q\dd y.
        \end{align}
        We can repeat the same argument for $\partialderivative{P}{y}.$
    \end{proof}
\end{theorem}
Green's theorem tells us that if $\partialderivative{P}{y},\partialderivative{Q}{x}$ exists and are continuous then $\int_\gamma=0$ for a sufficiently small rectangle $A$ iff $\int_A=\left(\partialderivative{Q}{x}-\partialderivative{Q}{y}\dd x\wedge\dd y\right)$ for sufficiently small rectangle $A$ iff $\partialderivative{Q}{x}-\partialderivative{P}{y}=0.$ This means that our definition of closed is equivalent to the MAT257 definition $(\dd\omega=0)$ when $\omega$ is $C^1.$

\begin{theorem}[Cauchy]
    If $f(z)$ is a holomorphic function in an open subset $\Omega\subseteq\C$ then the differential form $f(z)\dd z$ is closed.
    \begin{proof}[Proof (with additional assumption)] Let $z=x+iy,$ and additionally assume $\partialderivative{f}{x}$ and $\partialderivative{f}{y}$ exist and are continuous. Then, \begin{align}
        f(z)\dd z=f(z)\dd x+if(z)\dd y.
    \end{align}
    By Green's theorem, it is sufficient to show that $\partialderivative{f}{y}=i\partialderivative{f}{x}.$ This is the Cauchy-Riemann equation which holds because $f$ is holomorphic.
    
    \redbf{Warning:} \textcolor{red}{we do not want to use this assumption, because we will use Cauchy's theorem to prove that the partial derivatives are continuous. If we accept this proof, we accept} \redbf{circular reasoning}. 
    \end{proof}
    \begin{proof}[Proof (complete)]
        It suffices to show $\mu(R)=\int_\gamma f(z)\dd z=0$ when $\gamma$ is the boundary of any rectangle $R\subset\Omega.$ Let's divide $R$ into $4$ equal parts $R_i$; each with an oriented boundary $\gamma_i.$ Then, \begin{align}
            \int_\gamma f(z)\dd z&=\sum_{i=1}^4\int_{\gamma_i} f(z)\dd z.
        \end{align}
        So, for at least one $i,$ \begin{align}
            \left|\int_{\gamma_i} f(z)\dd z\right|&\geq\frac{1}{4}\left|\int_\gamma f(z)\dd z\right|,
        \end{align}
        for this $i,$ we define $\gamma^{(1)}=:\gamma_i,R^{(1)}=R_i.$ Hence, $|\mu(R^{(1)})|=\frac{1}{4}|\mu(R)|.$ If we continue to subdivide, we have $R\supset R^{(1)}\supset R^{(2)}\supset\cdots$ and $|\mu(R^{(n+1)})|\geq\frac{1}{4}|\mu(R^{(n)})|.$ Then, \begin{align}
            |\mu(R^{(n)})|=\int_{\gamma^{(k)}}f(z)\dd z\geq \frac{1}{4^k}\left|\int_\gamma f(z)\dd z\right|=\frac{1}{4^k}|\mu(R)|.
        \end{align}
        Then, we know $\exists! z_0\in\bigcup_k R^{(k)}.$ Since $f$ is holomorphic at $z_0$ then \begin{align}
            f(z)=f(z_0)+f'(z_0)(z-z_0)+\varphi(z)|z-z_0|
        \end{align}
        where $\lim_{z\to z_0}\varphi(z)=0$ i.e. $\forall\varepsilon>0\,\exists\delta>0$ s.t $|z-z_0|<\delta\implies|\varphi(z)|<\varepsilon.$ \begin{align}
            \int_{\gamma^{(k)}}f(z)\dd z=\int_{\gamma^{(k)}}f(z_0)\dd z+\int_{\gamma^{(k)}}f'(z_0)(z-z_0)\dd z+\int_{\gamma^{(k)}}\varphi(z)|z-z_0|\dd z.
        \end{align}
        The first two integrals are zero because their integrands have primitives. Given $\varepsilon>0,$ if $|z-z_0|<\delta$ then \begin{align}
            \left|\int_{\gamma^{(k)}}\varphi(z)|z-z_0|\dd z\right|&\leq\varepsilon\int_{\gamma^{(k)}}|z-z_0|\dd z\\
            &\leq\varepsilon\cdot\mathrm{diameter}(R^{(k)})\cdot\mathrm{perimeter}(R^{(k)})\\
            &=\varepsilon\cdot\frac{1}{2^k}\mathrm{diameter}(R)\cdot\frac{1}{2^k}\mathrm{perimeter}(R).\\
            &=\varepsilon\cdot\frac{1}{4^k}\mathrm{diameter}(R)\cdot\mathrm{perimeter}(R).
        \end{align}
        We know that \begin{align}
            |\mu(R)|\leq 4^k\left|\int_{\gamma^{(k)}}f(z)\dd z\right|\leq\varepsilon\cdot\mathrm{diameter}(R)\cdot\mathrm{perimeter}(R).
        \end{align}
        for any $\varepsilon>0,$ so $\mu(R)=0.$
    \end{proof}
\end{theorem}
\begin{corollary}
    If $f(z)$ is a holomorphic function in an open $\Omega\subset\C$ locally has a primitive, \textbf{which is also holomorphic}.
    \begin{proof}
        Consider the local primitive $F(z).$ Then, by definition $f(z)\dd z=\dd F.$ We know \begin{align}
            \dd F=\partialderivative{F}{z}\dd z+\partialderivative{F}{\bar z}\dd\bar z. 
        \end{align}
        We know $\partialderivative{F}{\bar z}=0$ because $\dd z$ and $\dd\bar z$ are linearly independent, so $F$ is holomorphic.
    \end{proof}
\end{corollary}
\begin{corollary}
    In Cauchy's theorem, it is enough to assume that $f$ is continuous in $\Omega$ and holomorphic outside a line parallel to the real axis. \begin{proof}
        Consider the following three cases: \begin{enumerate}
            \item If the rectangle does not intersect the line, then $f$ is holomorphic in the rectangle.
            \item If the boundary of the rectangle intersects the line, integrate over a slightly smaller rectangle that does not intersect the line. By continuity, the integral is the same as the difference between the rectangles approach zero.
            \item If the line intersects the interior of the rectangle, then split the region into two and integrate over the boundary of each of the smaller rectangle.
        \end{enumerate}
        This corollary extends to a finite union of lines.
    \end{proof}
\end{corollary}
\begin{theorem}
    Closed differential form $\omega$ in a \textbf{simply-connected} open subset $\Omega$ of $\R^2$ has a global primitive.
\end{theorem}
Next time we will show that a closed differential form $\omega=P\dd x+Q\dd y$ in an open $\Omega\subset\R^2$ always has a \textbf{primitive along a curve} $\gamma(t),t\in[a,b].$ i.e. a continuous function $f(t)$ s.t. for any $t_0\in[a,b]$ then \begin{enumerate}
    \item $\exists$ a primitive $F$ of $\omega$ in a neighborhood of $\gamma(t)$ s.t. $f(t)=F(\gamma(t))$ for $t$ sufficiently close to $t_0.$
\end{enumerate}

\subsection{Homotopy}
We want to know what is a primitive of a closed differential form? We know this is not always the case, but \begin{proposition}
    $\Omega\subset\R^2$ open and $\omega$ closed differential form in $\Omega.$ Let $\gamma:[a,b]\to\Omega$ be a continuous curve. Then, there is a continuous function $f(t)$ on $[a,b]$ s.t. for every $t_0\in[a,b]$ there is a primitive $F$ of $\omega$ in a neighborhood of $\gamma(t_0)$ s.t. $f(t)=F(\gamma(t))$ for $t$ in a neighborhood of $t_0.$ $f$ is uniquely determined up to a constant.
    \begin{proof}[Proof (Uniqueness)]
        Suppose $f_1,f_2$ are primitives of $\omega$ along $\gamma.$ Then in a neighborhood of $t_0,$ then $f_1(t)-f_2(t)=F_1(\gamma(t))-F_2(\gamma(t)).$ $F_1$ and $F_2$ are local primitives of $\omega$ in the same neighborhood, so they differ by a constant. Since $f_1-f_2$ is locally constant and $f_1-f_2$ is continuous, $f_1-f_2$ is constant.
    \end{proof}
    \begin{proof}[Proof (Existence)]
        There is a primitive $a=t_0<t_1<\cdots<t_n=b$ of $[a,b]$ s.t. every $\gamma([t_{i-1},t_i])$ lies in an open disk $U_i$ in which $\omega$ has a primitive $F_i.$ The partition is finite because the curve is compact. We know that $U_i\cap U_{i+1}$ is connected, that $F_{i+1}-F_i$ is constant in $U_i\cap U_{i+1}$. Hence, we can choose the constants step-by-step to make $F_i=F_{i+1}$ in $U_i\cap U_{i+1}.$ Then define $f(t)=F_i(\gamma(t)).$
    \end{proof}
\end{proposition}

If $\gamma$ is piecewise $C^1$ and $f$ is a primitive of $\omega$ along $\gamma,$ then $\int_\gamma\omega=f(b)-f(a).$ Consider a partition $\gamma_i=:\gamma|_{[t_{i-1},t_i]}.$ Then, \begin{align}
    \int_\gamma\omega=\sum_i\int_{\gamma_i}\omega=\sum_i\big(F_i(\gamma(t_i))-F_i(\gamma(t_{i-1}))\big)=f(b)-f(a).
\end{align}
So we can define $\int_\gamma\omega$ where $\gamma$ is a continuous curve as $f(b)-f(a).$

Example: Let $\gamma$ be a closed curve about the origin. What is $\int_\gamma\dd z/z=f(b)-f(a)=$ the difference between two branches of $\log$ at $\gamma(a)=\gamma(b),$ which is $2\pi in$ for $n\in\Z.$

Let the real differential form $\int_\gamma\frac{x\dd y-y\dd x}{x^2+y^2}=2\pi n,$ the difference between two branches of $\arctan.$ This is called the \bluebf{variation of $\arg z$ along $\gamma.$} We use this definition even if $\gamma$ is not closed.

\begin{definition}[Homotopy]
    $\gamma_0,\gamma_1:[0,1]\to\Omega$ continuous curves with the same endpoints are \bluebf{homotopic with fixed endpoints in $\Omega$} if there is a continuous function $\gamma:[0,1]^2\to\Omega$ such that.\begin{align}
        \gamma(0,t)&=\gamma_0(t),\\
        \gamma(1,t)&=\gamma_1(t),\\
        \gamma(s,0)&=\gamma_0(0)=\gamma_1(0),\\
        \gamma(s,1)&=\gamma_0(1)=\gamma_1(1).
    \end{align}
    $\gamma_0,\gamma_1:[0,1]\to\Omega$ that are continuous closed curves are \bluebf{homotopic as closed curves in $\Omega$} if there is a continuous function $\gamma:[0,1]^2\to\Omega$ such that.\begin{align}
        \gamma(0,t)&=\gamma_0(t),\\
        \gamma(1,t)&=\gamma_1(t),\\
        \gamma(s,0)&=\gamma(s,1).
    \end{align}
    If $\gamma_1$ is constant, then $\gamma_0$ is \bluebf{homotopic to a point}.
\end{definition}
\begin{definition}[Simply Connected]
    $\Omega$ is \bluebf{simply connected} if every closed curve in $\Omega$ is \bluebf{null homotopic} (homotopic to a point). There are the following equivalent definitions \begin{itemize}
        \item Any two curves with the same endpoints are homotopic with fixed endpoints.
    \end{itemize}
\end{definition}

\begin{theorem}
    If $\omega$ is a closed differential form in $\Omega$ and $\gamma_0,\gamma_1:[0,1]\to\Omega$ are continuous curves which are homotopic (either with fixed endpoints or as closed curves), then $\int_{\gamma_0}\omega=\int_{\gamma_1}\omega.$
    \begin{proof}[Proof (Hint)]
        What we started today by showing that a differential form always has a primitive along a curve. A curve is a mapping from $[0,1]\to\Omega.$ There is nothing in the argument that required us to work on an interval. We can also work on a rectangle. What's true is that it always exists a primitive that exists from $[0,1]^2\to\Omega$ If we extend a proof to a square, this theorem is a very simple conclusion.
    \end{proof}

    \begin{lemma}
        Suppose $\omega$ is a closed form in $\Omega$ and $\gamma:[a,b]\times[c,d]\to\Omega$ is a continuous function. Then, there is a continuous function $f:[a,b]\times[c,d]\to\C$ s.t. for every point $(s_0,t_0)\in[a,b]\times[c,d]$ there is a local primitive $F$ of $\omega$ defined in a neighborhood of $\gamma(s_0,t_0)$ s.t. $f=F(\gamma(s,t))$ in a neighborhood of $(s_0,t_0).$ Moreover, $f$ is unique up to the addition of a constant.
        \begin{proof}
            Choose partitions $\{s_i\}$ of $[a,b]$ and $\{t_j\}$ of $[c,d]$ s.t. $\gamma$ maps every $[s_{i-1},s_i]\times[t_{j-1},t_j]$ into an open disk $U_{ij}$ where $\omega$ has a primitive $F_{ij}.$

            For a fixed $j,$ there is a primitive $f_j$ along $\gamma|_{[a,b]\times[t_{j-1},t_j]}$ like before. ($F_{ij},F_{i+1,j}$ differ by a constant in $U_{ij}\cap U_{i+1,j}$ So, we can adjust these constants one at a time to make them equal in the intersection.)

            Then we can define $f_j$ as $F_{ij}\circ\gamma$ in $[s_{i-1},s_i]\times[t_{j-1},t_j].$ For each $j,$ on $[a,b]\times\{t_j\}.$ On that line, both $f_j$ and $f_{j+1}$ are primitives along a curve, so they differ by a constant. So, we can again adjust these constants so $f_j=f_{j+1}$ on $[a,b]\times\{t_j\}.$

            Then we can define $f$ as $f_j$ in $[a,b]\times[t_{j-1},t_j].$
        \end{proof}
    \end{lemma}
    \begin{proof}[Proof (fixed endpoints)]
        We have homotopy $\gamma:[0,1]\times[0,1]\to\Omega$ with fixed endpoints. Let $f$ be a primitive of $\omega$ along $\gamma.$ We know $f$ is constant on $t=0$ and $t=1$ because $\gamma$ is constant. So, $f(0,0)=f(1,0)$ and $f(0,1)=f(1,1).$ We know $f$ is a primitive of $\omega,$ so \begin{align}
            \int_{\gamma_0}\omega&=f(0,1)-f(0,0)\\
            \int_{\gamma_1}\omega&=f(1,1)-f(1,0),
        \end{align}
        thus they are equal.
    \end{proof}
    \begin{corollary}
        In a simply connected open set, any closed form has a primitive.
    \end{corollary}
\end{theorem}
\begin{definition}[Star-Shaped]
    $\Omega$ is \bluebf{star-shaped} if $\exists a\in\Omega$ s.t. for every $x\in\Omega,$ the line segment $\{(1-t)a+tx|t\in[0,1]\}\subseteq\Omega.$
\end{definition}
We will present some examples:
\begin{enumerate}
    \item A star shaped open set $\Omega$ is simply connected. For any curve, $\gamma:[0,1]\to\Omega,$ choose $\gamma(s,t)=a+s(\gamma(t)-a)$ which is a homotopy between $\gamma$ and the point $a.$
    \item Closed form $\omega=\dd z/z$ has a primitive in any simply connected open set $\Omega$ not containing $0.$ i.e. $\log z$ has a branch in any simply connected open set not containing $0.$ Hence, we can define \begin{align}
        \log z=w_0+\int_{z_0}^z\frac{\dd z'}{z'}\qquad\text{where }e^{w_0}=z_0.
    \end{align}
    
    \item $\C\setminus\{0\}$ is not simplify connected. $S^1$ is not homotopic to a point in $\C\setminus\{0\}$ because $\int_{S^1}\dd z/z=2\pi i\neq0.$
\end{enumerate}
\begin{definition}[Winding Number]
    Let $\gamma:[0,1]\to\C$ be a closed curve and $a$ be a point not on $a.$ The \bluebf{winding number} of $\gamma$ w.r.t $a$ is \begin{align}
        w(\gamma,a)=\frac{1}{2\pi i}\int_{\gamma}\frac{\dd z}{z-a}.
    \end{align}
\end{definition}
Observe the following properties \begin{enumerate}
    \item $w(\gamma,a)\in\Z.$
    \item Fix $a,$ then $w(\gamma,a)$ is invariant under homotopy of $\gamma$ not passing through $a$ (by the previous theorem).
    \item In particular, if $\gamma$ lies in a simply connected open set not containing $a,$ then $w(\gamma,a)=0.$
    \item Fix $\gamma,$ then $w(\gamma,a)$ is constant on connected components of $\C\setminus\gamma([0,1]).$ It suffices to show that $w(\gamma,a)$ is locally constant. A small shift of $a$ is equivalent to the same shift of $\gamma$ in the opposite direction, which is a homotopy not passing through $a.$
    \item If $\gamma$ is a circle described in \textbf{positive sense} (w.r.t to the center $c,w(\gamma,c)=1.$) Then, $w(\gamma,a)=0$ when $a$ is outside $\gamma$ and $w(\gamma,a)=1$ when $a$ is inside $\gamma.$
\end{enumerate}
\begin{theorem}[Cauchy's Integral Formula]
    For an open set $\Omega\subseteq\C,$ a point $a\in\C$ a holomorphic function in $\Omega,$ $f(z)$ and a closed curve $\gamma:[0,1]\to\Omega$ not containing $a$ that is homotopic to a point in $\Omega.$ Then, \begin{align}
        \frac{1}{2\pi i}\int_\gamma\frac{f(z)}{z-a}\dd z=w(\gamma,a)\cdot f(a).
    \end{align}
    \begin{proof}
        Let \begin{align}
            g(z)&=\begin{cases}
                \frac{f(z)-f(a)}{z-a}&\text{if }z\neq a\\
                f'(a)&\text{if }z=a
            \end{cases}.
        \end{align}
        We know $g(z)$ is continuous, and holomorphic when $z\neq a.$ By Cauchy's theorem, $g(z)\dd z$ is closed. Thus, \begin{align}
            0&=\int_\gamma g(z)\dd z=\int_\gamma\frac{f(z)-f(a)}{z-a}\dd z
        \end{align}
        i.e. \begin{align}
            \int_\gamma\frac{f(z)}{z-a}\dd z&=f(a)\int_\gamma\frac{\dd z}{z-a}=f(a)\cdot 2\pi iw(\gamma,a).
        \end{align}
    \end{proof}
\end{theorem}
\begin{corollary}
    If $f(z)$ is holomorphic in a neighborhood of a closed disk $D$ and $\gamma=\partial D$ then \begin{align}
        \frac{1}{2\pi i}\int_\gamma\frac{f(z)}{z-a}=\begin{cases}
            f(a)&\text{if }a\in D\\
            0&\text{otherwise}
        \end{cases}
    \end{align}
\end{corollary}
\begin{corollary}
    A holomorphic function $f(z)$ in an open set in $D$ is infinitely differentiable in $D.$ Fix some smaller disk containing $z$ with boundary $\gamma.$ By Cauchy's integral formula, \begin{align}
        f(z)=\frac{1}{2\pi i}\int_\gamma\frac{f(\zeta)\dd\zeta}{\zeta-z}.
    \end{align}
    Then we can differentiate under the integral sign so \begin{align}
        f(z)=\frac{1}{2\pi i}\int_\gamma\derivative{}{z}\frac{f(\zeta)\dd\zeta}{\zeta-z}=\frac{1}{2\pi i}\int_\gamma\frac{f(\zeta)\dd\zeta}{(\zeta-z)^2}.
    \end{align}
    In fact, \begin{align}
        f^{(n)}(z)=\frac{n!}{2\pi i}\int_\gamma\frac{f(\zeta)\dd\zeta}{(\zeta-z)^{n+1}}.
    \end{align}
\end{corollary}
\begin{theorem}[Morera]
    If $f(z)\dd z$ is a closed form, then $f(z)$ is holomorphic.
    \begin{proof}
        If $f(z)\dd z$ is a closed form, then $f(z)$ locally has a primitive $g(z)$ which is holomorphic. Then, $f(z)=g'(z)$ is also holomorphic.
    \end{proof}
\end{theorem}
\begin{corollary}
    A continuous function which is holomorphic except on a finitely many line is holomorphic everywhere.
\end{corollary}
We can wrap up the previous theorem as follows. Consider $f(z)$ is a continuous function in $\Omega.$ Then, the following are equivalent \begin{enumerate}
    \item $f(z)$ is holomorphic in $\Omega.$
    \item $f(z)\dd z$ is closed.
    \item $\displaystyle{f(z)=\frac{1}{2\pi i}\int_\gamma\frac{f(\xi)}{\xi-z}\dd\xi}$ when $z$ is in the interior of a closed disk $D$ in $\Omega,$ with oriented boundary $\gamma.$
\end{enumerate}
$(1)\implies(2)$ is cauchy's theorem, $(2)\implies(3)$ is cauchy's integral formula, $(3)\implies(2)$ is the corollary, and $(2)\implies(1)$ is Morera's theorem.

Applications of Cauchy's Integral Formula: Let $f(z)$ be holomorphic in the disk $|z|<R.$ Let $r$ be any number $0<r<R,$ then if $z<r$ then \begin{align}
    f(z)=\frac{1}{2\pi i}\int_\gamma\frac{f(\zeta)}{\zeta-z}\dd\zeta\qquad f^{(n)}(z)=\frac{n!}{2\pi i}\int_\gamma\frac{f(\zeta)}{(\zeta-z)^{n+1}}\dd\zeta.
\end{align}
This allows us to write the power series expansion of $f$ at $0$ $f(z)=\sum a_nz^n.$ \begin{align}
    a_n=\frac{f^{(n)}(0)}{n!}=\frac{1}{2\pi i}\int_\gamma\frac{f(\zeta)}{\zeta^{n+1}}\dd\zeta.
\end{align}
\begin{theorem}
    $f(z)$ has a convergent power series expansion in $|z|<R.$
    \begin{proof}
        Note that \begin{align}
            \frac{1}{\zeta-z}=\frac{1}{\zeta}\left(1-\frac{z}{\zeta}\right)^{-1}=\frac{1}{\zeta}\sum_{n=0}^\infty\frac{z^n}{\zeta^n},
        \end{align}
        this is a geometric series which converges for $|z|<|\zeta|=r.$ Then, we can substitute this expression \begin{align}
            f(z)=\frac{1}{2\pi i}\int_\gamma\sum_{n=0}^\infty \frac{z^n f(\zeta)}{\zeta^{n+1}}\dd\zeta.
        \end{align}
        For fixed $z,$ and $|z|<r,$ this is uniformly convergent by comparison with geometric series. So, the integral and the sum commute.
        \begin{align}
            f(z)=\sum_{n=0}^\infty\frac{z^n}{2\pi i}\int_\gamma\frac{f(\zeta)}{\zeta^{n+1}}\dd\zeta.
        \end{align}
    \end{proof}
\end{theorem}
\begin{corollary}
    Every holomorphic function is analytic.
\end{corollary}
We can write the power series expansion as a fourier series by using $z=re^{i\theta},$ then \begin{align}
    f(z)=\sum_{m=0}^{\infty}a_mr^me^{im\theta}.
\end{align}
We can multiply both sides by $e^{in\theta}$ and integrate from $0$ to $2\pi,$ then \begin{align}
    a_nr^n=\frac{1}{2\pi}\int_0^{2\pi}f(re^{i\theta})e^{in\theta}\dd\theta.
\end{align}
We can also see this by integration by substitution $\zeta=re^{i\theta},\dd\zeta=ire^{i\theta}\dd\theta.$ This integral formula gives an upper bound for the taylor coefficients. Let $M(r)=\sup_\theta|f(re^{i\theta})|.$ Then. $|a_nr^n|\leq|M(r)|$ so $|a_n|\leq|M(r)|/r^n.$ These are called \bluebf{Cauchy's Inequalities}.
\begin{theorem}[Liouville]
    A bounded holomorphic function in $\C$ is constant.
    \begin{proof}
        $M(r)\leq M$ for some $M$ since $f$ is bounded. So, $|a_n|\leq M/r^n$ for all $r>0,$ so if $n\geq1,$ then $a_n=0$ and $f(z)=a_0$ is constant. 
    \end{proof}
\end{theorem}
\begin{corollary}
    \textbf{Fundamental theorem of algebra.} Any non-constant polynomial on $\C$ has a root.
    \begin{proof}
        By contradiction suppose a polynomial $P(z)$ has no root. Then, $1/P(z)$ is a holomorphic function on $\C$ and its bounded. Therefore, it is constant so $P(z)$ is constant. 
    \end{proof}
\end{corollary}
\begin{theorem}[Schwartz's reflection principle]
    Let $\Omega\subseteq\C$ be a domain that is symmetric with respect to the real axis. Let $\Omega^+=\{z\in\Omega|\Im(z)\geq0\},\Omega^-=\{z\in\Omega|\Im(z)\leq0\}.$ Let $f(z)$ be continuous on $\Omega^+,$ real on $\Omega\cap\R$ and holomorphic in $\Omega^{+}\setminus\R,$ then $f(z)$ extends to a holomorphic function in $\Omega$ (and it is unique by the principle of analytic continuation).
    \begin{proof}
        Define $g(z)=\begin{cases}
            f(z)& z\in\Omega^+\\
            \overline{f(\bar z)} & z\in\Omega^-
        \end{cases}.$ Then we know $g(z)$ is holomorphic in $\Omega\setminus\R.$ $g$ is continuous on $\Omega$ also therefore $g$ is holomorphic in $\Omega.$
    \end{proof}
    A more general form of this result can apply to any line (with the image on another line). Similarly to a circle.
\end{theorem}
\end{document}
